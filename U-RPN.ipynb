{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPN\n",
    "\n",
    "Afegim a la U-Net una branca nova, la branca de *region proposal network (RPN)*.  Introduida per primer cop per la *faster rcnn* duu a terme dues tasques alhora, per una part refina tot un conjunt de <a hfre=\"https://www.termcat.cat/ca/cercaterm/bounding%20box?type=basic\">envolupants </a> i per l'altra indica quina és la probabilitat que cada un d'ells contengui un objecte.\n",
    "\n",
    "<img style=\"width:75%\" src=\"https://www.researchgate.net/publication/333048961/figure/fig1/AS:758094162296847@1557755141554/The-framework-of-Faster-R-CNN-RPN-region-proposal-network-RoI-region-of-interest-FC.ppm\" />\n",
    "\n",
    "### Importam llibreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import colorsys\n",
    "import random\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import sys\n",
    "\n",
    "import cv2 \n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import patches,  lines\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras.layers as keras_layer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils as KU\n",
    "import keras\n",
    "\n",
    "\n",
    "# Llibraries pròpies\n",
    "from u_rpn.data import unet as u_data\n",
    "from u_rpn.data import rpn as rpn_data\n",
    "from u_rpn.data import datasets as rpn_datasets\n",
    "from u_rpn import model as u_model\n",
    "from u_rpn import configurations as u_configs\n",
    "from u_rpn.common import data as common_data\n",
    "from u_rpn import layers as own_layers\n",
    "from u_rpn.losses import bce\n",
    "from u_rpn import losses as rpn_losses\n",
    "from u_rpn.common import utils as rpn_utils\n",
    "from u_rpn.common import metrics as rpn_metrics\n",
    "\n",
    "\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Optimisation Flags - Do not remove\n",
    "# ============================================\n",
    "\n",
    "os.environ['CUDA_CACHE_DISABLE'] = '0'\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT'] = '1'\n",
    "\n",
    "os.environ['TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT'] = '1'\n",
    "\n",
    "os.environ['TF_ADJUST_HUE_FUSED'] = '1'\n",
    "os.environ['TF_ADJUST_SATURATION_FUSED'] = '1'\n",
    "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "\n",
    "os.environ['TF_SYNC_ON_FINISH'] = '0'\n",
    "os.environ['TF_AUTOTUNE_THRESHOLD'] = '2'\n",
    "os.environ['TF_DISABLE_NVTX_RANGES'] = '1'\n",
    "\n",
    "# ================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def draw_bboxes(img, bboxes, thickness=3):\n",
    "    img = np.copy(img.astype(np.uint8))\n",
    "    colors = random_colors(len(bboxes))\n",
    "\n",
    "    for bbox, color in zip(bboxes, colors):\n",
    "        color = np.array(color) * 255\n",
    "        img = cv2.rectangle(img, (bbox[1], bbox[0]), (bbox[3], bbox[2]), color, thickness)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def make_masks(mask, slice_mask):\n",
    "    if isinstance(slice_mask, list):\n",
    "        if len(slice_mask) != 2:\n",
    "            raise ValueError\n",
    "        \n",
    "        mask = np.sum(mask[:,:, slice_mask[0]:slice_mask[1]], axis=-1)\n",
    "    elif isinstance(slice_mask, list):\n",
    "        mask = mask[:, :, slice_mask]\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuració\n",
    "\n",
    "Primerament cream un classe configuració per l'execusió i entrenament de la xarxa. En aquesta classe deixam els valors per defecte exceptuant els casos del nombre de classes, la mida de les ancores, les pases per època i el llindar mínim de confiança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_CLASS = False\n",
    "PYRAMID = False\n",
    "TRANSFER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = u_configs.CellConfig()\n",
    "\n",
    "# Number of classes (including background)\n",
    "if MULTI_CLASS:\n",
    "    NUM_CLASSES = 1 + 3  # Background + 3 classes\n",
    "else:\n",
    "    NUM_CLASSES = 1 + 1  # Background + 3 classes\n",
    "        \n",
    "config.IMAGE_SHAPE = np.array([128,128, 3])\n",
    "config.BATCH_SIZE = 2\n",
    "config.DO_MERGE_BRANCH = False\n",
    "config.DO_MASK_CLASS = False\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament\n",
    "\n",
    "Per realitzar l'entrenament primerament cream dos generadors d'imatges. Els generadors en el cas de la *RPN* es creen en dos temps. Primerament cream objectes **Dataset**.\n",
    "\n",
    "![SegmentLocal](https://imgs.xkcd.com/comics/ai_methodology.png \"segment\")\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Definim un objecte Dataset. Anàlogament a la configuració, ja definida, és basa en herència de classes abstractes definides a les llibreries. Un detall important és que en el cas de la RPN les dades es formen a partir dels envolupants, enlloc de l'inrevés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_val = rpn_datasets.ErithocytesDataset([(\"cell\", 1, \"cell\")], \"bboxes.json\")\n",
    "dataset_val.load_cell(\"./in/eritocitos_augmented/\", rpn_datasets.Subset.VALIDATION)\n",
    "dataset_val.prepare()\n",
    "\n",
    "val_generator = rpn_data.DataGenerator(2, dataset_val, config, shuffle=False)\n",
    "anchors = val_generator.anchors.tolist()\n",
    "\n",
    "if JUMBO:\n",
    "    dataset = rpn_datasets.ErithocytesPreDataset(\n",
    "        \"./in/jumbo2_mini/train\", \"data.json\", divisor=1\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    dataset = rpn_datasets.ErithocytesPreDataset(\"./in/pre_calculate/train\", \"data.json\", divisor=255)\n",
    "\n",
    "dataset.prepare()\n",
    "\n",
    "generator = rpn_data.DataGenerator(\n",
    "    50, \n",
    "    dataset, \n",
    "    pre_calculated=True,\n",
    "    config=config,\n",
    "    phantom_output=True, \n",
    "    shuffle=False,\n",
    "    size_anchors=dataset.anchors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, _ in generator:\n",
    "    break\n",
    "for d in data:\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construim el model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageHistory(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, data, tensor_board_dir: str, draw_interval: int = 1,  *args, **kwargs):\n",
    "        self.tensor_board_dir = tensor_board_dir\n",
    "        self.draw_interval = draw_interval\n",
    "        self.data = data\n",
    "        self._last_step = 0\n",
    "        \n",
    "        super(ImageHistory, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        for item in self.data:\n",
    "            y_pred = self.model.predict(item)\n",
    "            self.saveToTensorBoard(y_pred[0][0,:,:,:1].reshape(1, 512, 512, 1), y_pred[0][0,:,:,1:2].reshape(1, 512, 512, 1))\n",
    "                \n",
    "    def saveToTensorBoard(self, img1, img2):\n",
    "        writer = tf.summary.create_file_writer(self.tensor_board_dir)\n",
    "        \n",
    "        with writer.as_default():\n",
    "            tf.summary.image(\"TD 1\", img1, step=self._last_step)\n",
    "            tf.summary.image(\"TD 2\", img2, step=self._last_step)\n",
    "            self._last_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.no_gradient(\"CombinedNonMaxSuppression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urpn = u_model.u_rpn.URPN(\n",
    "        config=config,\n",
    "        mode=u_model.keras_rpn.NeuralMode.TRAIN,\n",
    "        anchors=anchors,\n",
    "        input_size=(128, 128, 3),\n",
    "        decoder_output=u_model.decoder.SuperDecoderOutput,\n",
    "        input_sd=(128, 128),\n",
    "        cell_shape=(9, 9),\n",
    "        filters=32,\n",
    "        decoder_output_size=3\n",
    "    )\n",
    "\n",
    "urpn.compile(optimizer=tf.keras.optimizers.Adadelta(config.LEARNING_RATE),\n",
    "             run_eagerly=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./check/checkpoint.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "urpn.internal_model.fit(\n",
    "    generator,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferència\n",
    "\n",
    "\n",
    "![SegmentLocal](https://c.tenor.com/kWejy2kDcTwAAAAC/office.gif \"segment\") \n",
    "\n",
    "### JUMBO\n",
    "\n",
    "Sortida amb múltiples cel·les i multiples màscares per cel·la. Els objectes inclosos dins cada cel·la són segmentat per aquestes màscares. Similar a la idea de Wang *et al.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urpn.internal_model.load_weights(\"./check/checkpoint.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = urpn.internal_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pred:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[p < 0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "for i in range(80):\n",
    "    plt.subplot(9, 9, i+1)\n",
    "    cell_x = int(i // 9)\n",
    "    cell_y = int(i % 9)\n",
    "    plt.imshow(p[0, :, :, cell_x, cell_y, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORMAL\n",
    "\n",
    "Per realitzar la inferència generam un nou model, amb el mode ``INFERENCE``. Una vegada creat hem de carregar els pesos des d'un fitxer, generat quan acabam l'entrenament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rpn = build_model(u_model.rpn.NeuralMode.INFERENCE, config, True)\n",
    "rpn.load_weights(\"./check/checkpoint.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (t, _) in enumerate(train_generator):\n",
    "    break\n",
    "    \n",
    "if True:\n",
    "    masks, cls, bboxes, msk_cls, mask_branch = rpn.internal_model.predict(t[0])\n",
    "else:\n",
    "    masks, _, cls, bboxes, _, _, _, msk_cls = rpn.internal_model.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mask class - Pred {np.count_nonzero(msk_cls[0] > 0.5)} | GT {np.count_nonzero(t[4][0] > 0.5)}\")\n",
    "print(\"***\"*10)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Masks\")\n",
    "\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(36):\n",
    "    plt.subplot(6, 6, i + 1)\n",
    "    mask = masks[0,:,:,i]\n",
    "    mask[mask < 0.6] = 0 \n",
    "    plt.imshow(mask, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = [64, 0, 448, 512]\n",
    "ORG_IMG = [2352, 3136, 3]\n",
    "IMG_SHAPE = [512, 512, 3]\n",
    "\n",
    "def predict_and_show(org_img, threshold):\n",
    "    in_img_m_r, window, _, _, _ = rpn_utils.resize_image(org_img, min_dim = 512, max_dim=512, mode=config.IMAGE_RESIZE_MODE)\n",
    "    in_img_m = val_generator.mold_image(in_img_m_r)\n",
    "    \n",
    "    img_batch = np.repeat(in_img_m.reshape((1, 512, 512, 3)), 5, axis=0)\n",
    "    masks, cls, bboxes, msk_cls = rpn.predict(img_batch)\n",
    "\n",
    "    # mask_pred, cls, bboxes, msk_cls = rpn.predict(img.reshape(1, 512, 512, 3))\n",
    "\n",
    "    bboxes_deltas = bboxes[0] * config.RPN_BBOX_STD_DEV\n",
    "    bboxes_deltas = val_generator.decode_deltas(bboxes_deltas)\n",
    "\n",
    "    bboxes_filtered = bboxes_deltas[cls[0][:, 1] > threshold]\n",
    "    cls =  cls[0][:, 1][cls[0][:, 1] > threshold]\n",
    "\n",
    "    inside_the_box = ((bboxes_filtered[:, 0] > WINDOW[0] + 5) & \n",
    "                       (bboxes_filtered[:, 1] > WINDOW[1] + 5) & \n",
    "                       (bboxes_filtered[:, 2] < WINDOW[2] - 5) & \n",
    "                       (bboxes_filtered[:, 3] < WINDOW[3] - 5))\n",
    "    print(len(bboxes_filtered))\n",
    "    bboxes_filtered = bboxes_filtered[inside_the_box]\n",
    "    cls = cls[inside_the_box]\n",
    "    print(len(bboxes_filtered))\n",
    "    \n",
    "\n",
    "    bboxes_filtered = common_data.non_max_suppression_fast(bboxes_filtered, 0.3, cls)\n",
    "    print(len(bboxes_filtered))\n",
    "    \n",
    "    res = draw_bboxes(in_img_m_r, bboxes_filtered, 1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img = skimage.io.imread(\"./in/bboxes_class/val/5.png\")\n",
    "\n",
    "img = predict_and_show(org_img, 0.9)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in rpn.internal_model.layers:\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn.internal_model.layers[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "XX = rpn.internal_model.input \n",
    "YY = rpn.internal_model.layers[31].output\n",
    "new_model = Model(XX, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img_m_r, window, _, _, _ = rpn_utils.resize_image(org_img, min_dim = 512, max_dim=512, mode=config.IMAGE_RESIZE_MODE)\n",
    "in_img_m = val_generator.mold_image(in_img_m_r)\n",
    "\n",
    "img_batch = np.repeat(in_img_m.reshape((1, 512, 512, 3)), 5, axis=0)\n",
    "out = new_model.predict(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "aux = np.sum(out, axis=-1)\n",
    "plt.imshow(aux[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = t[1].astype(np.float64)\n",
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(16):\n",
    "    plt.subplot(8, 4, i + 1)\n",
    "    plt.imshow(out[0,:,:,i])\n",
    "    \n",
    "    plt.subplot(8, 4, 16 + (i + 1))\n",
    "    plt.imshow(gt[0,:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mètriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "THRESH = 0.9\n",
    "gt_g = []\n",
    "p_g = []\n",
    "\n",
    "dataset = dataset_val\n",
    "generador = val_generator\n",
    "resultats = []\n",
    "diff_gen = 0\n",
    "for idx in tqdm(dataset.image_ids):\n",
    "    org_img, _, _ , gt_bbox, mask_gt = rpn_data.DataGenerator.load_image_gt(dataset, config, idx)\n",
    "    img = np.copy(org_img)\n",
    "    \n",
    "    img = generador.mold_image(img)\n",
    "    mask_pred, cls, bboxes, msk_cls = rpn.predict(img.reshape(1, 512, 512, 3))\n",
    "    \n",
    "    bboxes_deltas = bboxes[0] * config.RPN_BBOX_STD_DEV\n",
    "    bboxes_deltas = generador.decode_deltas(bboxes_deltas)\n",
    "    \n",
    "    bboxes_filtered = bboxes_deltas[cls[0][:, 1] > THRESH]\n",
    "    cls =  cls[0][:, 1][cls[0][:, 1] > THRESH]\n",
    "\n",
    "    inside_the_box = ((bboxes_filtered[:, 0] > WINDOW[0] + 5) & \n",
    "                       (bboxes_filtered[:, 1] > WINDOW[1] + 5) & \n",
    "                       (bboxes_filtered[:, 2] < WINDOW[2] - 5) & \n",
    "                       (bboxes_filtered[:, 3] < WINDOW[3] - 5))\n",
    "    \n",
    "    bboxes_filtered = bboxes_filtered[inside_the_box]\n",
    "    cls = cls[inside_the_box]\n",
    "    \n",
    "    bboxes_filtered = common_data.non_max_suppression_fast(bboxes_filtered, 0.3, cls)\n",
    "    res = draw_bboxes(org_img, bboxes_filtered, 1)\n",
    "    \n",
    "    img_path = os.path.join(\".\", \"out\", \"res\")\n",
    "    os.makedirs(img_path, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(img_path, f\"{idx}.png\"), res)\n",
    "    \n",
    "    _, _, pred = rpn_metrics.relate_bbox_to_gt(bboxes_filtered, gt_bbox)\n",
    "\n",
    "    gt_p = [1] * len(pred)\n",
    "\n",
    "    if len(pred) < len(bboxes_filtered):\n",
    "        diff = len(bboxes_filtered) - len(pred)\n",
    "        pred = pred + [1] * diff\n",
    "        gt_p = gt_p + [0] * diff\n",
    "        \n",
    "    gt_g = gt_g + gt_p\n",
    "    p_g = p_g + pred\n",
    "    metrics = list(rpn_metrics.basic_metrics(gt_p, pred))\n",
    "    \n",
    "    msk_cls[msk_cls < 0.5] = 0\n",
    "    diff = np.abs(mask_gt.shape[-1] - np.count_nonzero(msk_cls))\n",
    "    diff_gen += diff\n",
    "    \n",
    "    metrics.append(diff)\n",
    "#     rpn_losses.onw_dice_coefficient()\n",
    "    \n",
    "    resultats.append(metrics)\n",
    "\n",
    "diff_gen /= len(dataset.image_ids)\n",
    "resultats.append(list(rpn_metrics.basic_metrics(gt_g, p_g)) + [diff_gen])\n",
    "df = pd.DataFrame(resultats)\n",
    "df.columns = ['Precision BB', 'Recall BB', 'F1 BB', \"Diff MSK_CLS\"]\n",
    "\n",
    "# df.to_csv(os.path.join(img_path, \"resultats_experiment_.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(img_path, \"resultats_experiment_.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
