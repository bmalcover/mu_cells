{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ_9YMQZj-6V"
   },
   "source": [
    "# Classificació de cel·lules emprant la U-Net\n",
    "\n",
    "La xarxa U-Net és emprada per la generació de segmentacions, en particular en l'ambit mèdic. Introduïda per primer cop per *Ronneberger et al.*, aquesta xarxa es caracteritza per una estructura de codificador-decodificador i un conjunt de connexions saltejades. Aquestes característiques provoquen que sigui un model simple alhora que potent.\n",
    "\n",
    "<img style=\"width:50%\" src=\"https://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a/u-net-architecture.png\" />\n",
    "\n",
    "L'entrenament d'aquesta xarxa és el que s'anomena de cap a cap, això és així ja que tota la xarxa s'entrena de cop. Aquest fet és un dels que simplifiquen l'entrenament i permet l'ús de tècniques de augmentació de dades sense problemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4SSovO3EcTi"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Llibraries pròpies\n",
    "from u_cells.u_cells.unet import data as u_data\n",
    "from u_cells.u_cells.unet import model as u_model\n",
    "\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarregam les dades\n",
    "\n",
    "**IMPORTANT**: Només executar aquesta cel·la la primera vegada que s'executa la xarxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # !wget -O dataset_four.zip https://www.dropbox.com/s/0v6rdf3xhoge0vh/unet_color_quatre.zip?dl=1 \n",
    "    # !unzip dataset_four.zip > /dev/null\n",
    "    !wget -O nuclei_data.zip https://www.dropbox.com/s/wllznkxlw5jdj9u/nuclei_data.zip?dl=1\n",
    "    !unzip nuclei_data.zip > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_aL_C7ID6vK"
   },
   "source": [
    "## U-Net sense modificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paràmetres \n",
    "\n",
    "En aquesta cel·la definim tot un conjunt de paràmetres que emprarem per la xarxa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "TOTAL_IMAGES = 300\n",
    "STEPS_PER_EPOCH = TOTAL_IMAGES // BATCH_SIZE \n",
    "EPOCHS = 20\n",
    "\n",
    "TRAIN_PATH = './in/bboxes_class/train'\n",
    "TEST_PATH = './in/bboxes_class/val'\n",
    "\n",
    "RESET_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blX2Fvo1jw_J"
   },
   "source": [
    "En aquesta secció construeix entrena i testeja la xarxa U-Net original tal com es proposada per Ronnenberger et al.\n",
    "\n",
    "### Preparació de les dades i generació de les dades\n",
    "\n",
    "#### Generació de les dades\n",
    "\n",
    "La llibreria d'augmentació de dades s'executa a la CPU. Això suposa un coll de botella per l'entrenament, per tal de resoldre-ho el que hem fet és generar primer totes les imatges que emprarem, guardar-les a disc i després llegir-les. Això redueix considerablement el temps d'execució i a més permet un millor control del que passa, ja que tenim accés a les imatges.\n",
    "\n",
    "Per fer-ho empram la llibreria **ImgAug** de *Jung et al.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESET_DATA:\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    augmentation = [  # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5),  # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.2),  # vertically flip 20% of all images\n",
    "\n",
    "        sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                # scale images to 80-120% of their size, individually per axis\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-45, 45),  # rotate by -45 to +45 degrees\n",
    "                shear=(-16, 16),  # shear by -16 to +16 degrees\n",
    "                order=[0, 1],  # use nearest neighbour or bilinear interpolation (fast)\n",
    "                cval=0,  # if mode is constant, use a cval between 0 and 255\n",
    "                mode=ia.ALL\n",
    "                # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )),\n",
    "\n",
    "         iaa.SomeOf((0, 5),\n",
    "                   [\n",
    "                       iaa.OneOf([\n",
    "                           iaa.GaussianBlur((0, 3.0)),  # blur images with a sigma between 0 and 3.0\n",
    "                           iaa.AverageBlur(k=(2, 7)),\n",
    "                           # blur image using local means with kernel sizes between 2 and 7\n",
    "                           iaa.MedianBlur(k=(3, 11)),\n",
    "                           # blur image using local medians with kernel sizes between 2 and 7\n",
    "                           ]),\n",
    "                   ],\n",
    "                   random_order=True)]\n",
    "\n",
    "    u_data.generate_data(BATCH_SIZE * STEPS_PER_EPOCH, './in/bboxes_class/train/*.png', './out_aug/train/', augmentation, './in/bboxes_class/train/via_region_data.json', to_mask = True, output_shape=(512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generadors de Keras\n",
    "\n",
    "Una vegada hem creat i guardat les imatges augmentades a disc empram els generadors de keras per llegir la informació d'entrenament i validació. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = u_data.DataGenerator(BATCH_SIZE, STEPS_PER_EPOCH, './out_aug/train/*.png', (512, 512), \n",
    "                                       output_size = 100, augmentation=None, load_from_cache = True, \n",
    "                                       do_background = True, multi_type = True, binary_output = True)\n",
    "val_generator = u_data.DataGenerator(4, 10, TEST_PATH, (512, 512), output_size =  100, \n",
    "                                     region_path=\"via_region_data.json\", do_background = True, \n",
    "                                     multi_type = True, augmentation=None, binary_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, m in train_generator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(m['img_out'][0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cream el model\n",
    "\n",
    "Cream el model de la UNet, per fer-ho definim la mida de l'entrada, de la sortida i un parell de flags que determinen que farà la xarxa. \n",
    "\n",
    "A més també definim indicam la funció de pèrdua que emprarem i el nombre de filtres. Finalment també el nombre de blocs ( el mateix nombre pel codificador que pel descodificador ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = u_model.UNet(input_size=(None,None,3), out_channel=2, batch_normalization=False)\n",
    "\n",
    "model.build_unet(n_filters=64, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "model.compile(loss_func = clever_categorical, learning_rate = 3e-6, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ens interessa saber la forma del model. En particular la mida d'entrada i sortida de cada una de les capes, per tant feim una visualització per defecte de la llibreria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs2xII7Uj4AM"
   },
   "source": [
    "### Entrenament\n",
    "---\n",
    "\n",
    "Entrament de la xarxa. Els valors per defecte són 100 steps per validació, 300 per època d'entrenament i 10 èpoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWMmAPHnuku3"
   },
   "outputs": [],
   "source": [
    "model.train(train_generator, val_generator, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "            check_point_path=None, validation_steps=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history\n",
    "\n",
    "plt.figure(figsize=(9,6), dpi= 100, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# \"Loss\"\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregam un model preentrenat\n",
    "\n",
    "Podem carregar un model ja entrenat, per fer-ho el que necessitam es primer generar el model i després carragar-hi els pesos.\n",
    "\n",
    "*TODO: Automàticament selecionar els darrers pesos de la carpeta.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./out/model.02-0.02.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWPNcyPgwl_2"
   },
   "source": [
    "### Resultats - avaluació\n",
    "---\n",
    "Una vegada entrenat un model podem visualitzar els resulats, per fer-ho primer de tot cream un generador i després el feim prediccions. Obtenim també l'**IOU**. Definim un generador d'imatges de *test*. La seva principal característica es que no retorna cap GT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = json.load(open('./in/bboxes_class/val/via_region_data.json'))\n",
    "info = {k: (len(v[\"regions\"])) for k, v in info.items()}\n",
    "\n",
    "def testGenerator(test_path, target_size=(256, 256), flag_multi_class=False,\n",
    "                  as_gray=True, image=True):\n",
    "\n",
    "    filenames = glob.glob(test_path)\n",
    "    filenames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    # filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        path, name = os.path.split(filename)\n",
    "        print(f\"{filename=}\")\n",
    "        img = cv2.imread(filename)\n",
    "        img = img\n",
    "        img = skimage.transform.resize(img, target_size)\n",
    "        img = img.reshape(1, target_size[0], target_size[1], 3)\n",
    "\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPOE8fTaguPO"
   },
   "outputs": [],
   "source": [
    "testGene = testGenerator('./in/bboxes_class/val/*.png', target_size=(256, 256, 3), as_gray = False)\n",
    "masks  = model.model.predict(testGene, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi= 100, facecolor='w', edgecolor='k')\n",
    "mask_a = masks.astype(np.float64)\n",
    "suma = np.sum(mask_a[0, :, :, 0:1], axis=2)\n",
    "plt.imshow(suma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Fine tunning*\n",
    "\n",
    "Realitzam fine tunning. Per fer-ho congelam les primeres dotze capes i a partir de la 17 fins a la tercera començan pel final, l'objectiu: mantenir les features apreses i alhora refinar els resultats pel nostre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.model.layers:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.model.layers[:10]:\n",
    "    l.trainable = False\n",
    "    \n",
    "for l in model.model.layers[20:-3]:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = u_data.DataGenerator(BATCH_SIZE, STEPS_PER_EPOCH, './out_aug/train/*.png', (256, 256), 100, augmentation=None, load_from_cache = True, do_background = True, multi_type = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(model.model.optimizer.learning_rate, 3e-8) # Indicam un lr molt petit\n",
    "model.model.fit(train_generator, epochs=5, steps_per_epoch=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardam els resultats\n",
    "\n",
    "Guardam els resultats amb un fitxer per canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    for n_channel in range(0, masks.shape[3]):\n",
    "        path = os.path.join(\".\", \"out\", \"ccce\", \"img_\" + str(i).zfill(2))\n",
    "        os.makedirs(path, exist_ok = True)\n",
    "        \n",
    "        mask = masks[i, :, :, n_channel]\n",
    "        mask = mask / mask.max()\n",
    "        \n",
    "        cv2.imwrite(os.path.join(path, str(n_channel).zfill(4) + \".png\"), mask * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkfSD7SMVnUA"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIw2z80wvVXW"
   },
   "outputs": [],
   "source": [
    "def remove_border_cells(contours, shape):\n",
    "    \"\"\"\n",
    "    Removes the objects from the borders of the image.\n",
    "\n",
    "    A border of an image is the zone near the start or the end of the matrix. \n",
    "    The index of this points are near 0 and near the shape of the image. The \n",
    "    contours checked as a parameter don't has that exactly index so is needed \n",
    "    to has an acceptable error.\n",
    "\n",
    "    Args:\n",
    "        contours: List of numpy arrays, every array its a different contour. The array has two\n",
    "                  columns and many rows as points in the contour. Depending of the appoximation\n",
    "                  method used\n",
    "        shape:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    center_contours = []\n",
    "\n",
    "    for cont in contours:\n",
    "        cont = np.squeeze(cont)\n",
    "        border = not np.all(\n",
    "            (cont[:, 0] > 15) & (cont[:, 1] > 15) & (cont[:, 0] < shape[1] - 15) &\n",
    "            (cont[:, 1] < shape[0] - 15))\n",
    "\n",
    "        if not border:\n",
    "            center_contours.append(np.array([cont]).reshape((cont.shape[0], 1, \n",
    "                                                             cont.shape[1])))\n",
    "\n",
    "    return center_contours\n",
    "\n",
    "def get_iou(ground, prediction, th, debug=False, remove_border_segs = False):\n",
    "    assert ground.shape[2] == prediction.shape[2]\n",
    "  \n",
    "    ground = ground.astype(np.float32) / ground.max()\n",
    "    ious = [0] * ground.shape[2]\n",
    "  \n",
    "    if debug:\n",
    "        fig = plt.figure(1,(16, 12))\n",
    "        idx = 1\n",
    "\n",
    "    for channel_idx in range(0, ground.shape[2]):\n",
    "\n",
    "        channel_gt = ground[:,:, channel_idx]\n",
    "        channel_pred = np.copy(prediction[:, :, channel_idx])\n",
    "\n",
    "        channel_pred = cv2.resize(channel_pred, (channel_gt.shape[1], channel_gt.shape[0]), interpolation = cv2.INTER_NEAREST) \n",
    "\n",
    "        channel_pred[channel_pred <= th] = 0\n",
    "        channel_pred[channel_pred > th] = 1\n",
    "\n",
    "    if remove_border_segs:\n",
    "        contours, _ = cv2.findContours((channel_pred * 255).astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        contours = remove_border_cells(contours, channel_pred.shape)\n",
    "\n",
    "        channel_pred = np.zeros_like(channel_pred)\n",
    "        channel_pred = cv2.drawContours(channel_pred, contours, -1, 1, -1)\n",
    " \n",
    "    intersection = cv2.bitwise_and(channel_gt, channel_pred)\n",
    "    intersection_area = np.count_nonzero(intersection)\n",
    "    \n",
    "    union = cv2.bitwise_or(channel_gt, channel_pred)\n",
    "    union_area = np.count_nonzero(union)\n",
    "    \n",
    "    if debug:\n",
    "        l = [channel_gt, channel_pred, intersection, union, (union-intersection)]\n",
    "        titles = [\"GT\", \"PRED\", \"INTERSEC\", \"UNION\", \"DIFF\"]\n",
    "    \n",
    "        for i in range(len(l)):\n",
    "            plt.title(titles[(i-1) % 5])\n",
    "            plt.subplot(4,5, idx)\n",
    "            plt.imshow(l[i], cmap=\"gray\");\n",
    "            idx += 1\n",
    "    iou = 0\n",
    "    if union_area > 0:\n",
    "        iou = round(intersection_area / union_area, 3)\n",
    "\n",
    "    ious[channel_idx] += iou\n",
    "    \n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vh1u-AJDtS83"
   },
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "\n",
    "ious = []\n",
    "for idx, res in enumerate(results):\n",
    "    gt_image = cv2.imread(\"./unet_color_quatre/test/label/\" + str(idx) + \".png\")\n",
    "    # cv2 reads the images in BGR we convert them into rgb\n",
    "    gt_image = cv2.cvtColor(gt_image, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    gt_image = decode(gt_image, decode_mode.CELLS_BCK)\n",
    "\n",
    "    iou = get_iou(gt_image, res, alpha)\n",
    "    ious.append(iou)\n",
    "\n",
    "    if idx < 10:\n",
    "        print(\"Image 0\"+ str(idx) + \": \" + str(iou))\n",
    "    else:\n",
    "        print(\"Image \"+ str(idx) + \": \" + str(iou))\n",
    "\n",
    "print(\"###########################################\")\n",
    "print(\"Mean: \", np.mean(ious, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.imshow(res[:,:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jt6t3IqdNhH"
   },
   "source": [
    "La següent cel·la només serveix per evaluar el funcionament de _get_iou_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcRreiGbI76Q"
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "\n",
    "ground = cv2.imread(\"./unet_color_quatre/test/label/\" + str(index) + \".png\")\n",
    "ground = cv2.cvtColor(ground, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "prediction = results[index]\n",
    "th = 0.5\n",
    "ground = decode(ground)\n",
    "get_iou(ground, prediction, th, True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
