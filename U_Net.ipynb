{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ_9YMQZj-6V"
   },
   "source": [
    "# Classificació de cel·lules usant la U-Net\n",
    "\n",
    "**TODO: Descripcio**\n",
    "\n",
    "*La següent cel·la s'ha d'executar sempre*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_aL_C7ID6vK"
   },
   "source": [
    "**DATA**\n",
    "\n",
    "Només executar si dins la carpeta *u_net_folder* no hi ha la carpeta *unet_color_quatre*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLMGqb9qkYJG"
   },
   "source": [
    "Llibreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g4SSovO3EcTi"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import metrics\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRYXhO98TKQD"
   },
   "source": [
    "Funcionalitats propies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cLd9Ztk4Az92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miquel/UNet/u_cells\n",
      "/home/miquel/UNet\n"
     ]
    }
   ],
   "source": [
    "%cd u_cells/\n",
    "\n",
    "from model import *\n",
    "from data import *\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blX2Fvo1jw_J"
   },
   "source": [
    "### Preparació de les dades i generació de la xarxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gNJR2CqeEUX9"
   },
   "outputs": [],
   "source": [
    "train_path = './unet_color_quatre/train'\n",
    "test_path = './unet_color_quatre/test'\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2, \n",
    "                     width_shift_range=0.05,\n",
    "                     height_shift_range=0.05, \n",
    "                     shear_range=0.05, \n",
    "                     zoom_range=0.05, \n",
    "                     horizontal_flip=True,\n",
    "                     fill_mode='nearest')\n",
    "\n",
    "train_generator = trainGenerator(2, train_path,'image','label',data_gen_args, mask_color_mode = \"rgb\", decode_flag=True, target_size=(512,512)) #AQui\n",
    "val_generator = trainGenerator(2, './unet_color_quatre/test','image','label',data_gen_args, mask_color_mode = \"rgb\", decode_flag=True, target_size=(512,512)) #AQui\n",
    "\n",
    "model = get_small_unet(n_filters=64, bn = True, input_size=(512,512,1), output_channels = 4, loss_func = dice_coef_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs2xII7Uj4AM"
   },
   "source": [
    "### Entrenament\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FWMmAPHnuku3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33 images belonging to 1 classes.\n",
      "Found 33 images belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1817 - categorical_accuracy: 0.8084Found 17 images belonging to 1 classes.\n",
      "Found 17 images belonging to 1 classes.\n",
      "300/300 [==============================] - 169s 526ms/step - loss: 0.1814 - categorical_accuracy: 0.8087 - val_loss: 0.1655 - val_categorical_accuracy: 0.8323\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 152s 509ms/step - loss: 0.0461 - categorical_accuracy: 0.9522 - val_loss: 0.0532 - val_categorical_accuracy: 0.9375\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 154s 514ms/step - loss: 0.0318 - categorical_accuracy: 0.9668 - val_loss: 0.0429 - val_categorical_accuracy: 0.9499\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 154s 516ms/step - loss: 0.0262 - categorical_accuracy: 0.9723 - val_loss: 0.0441 - val_categorical_accuracy: 0.9492\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 153s 512ms/step - loss: 0.0221 - categorical_accuracy: 0.9756 - val_loss: 0.0424 - val_categorical_accuracy: 0.9514\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 153s 512ms/step - loss: 0.0196 - categorical_accuracy: 0.9779 - val_loss: 0.0405 - val_categorical_accuracy: 0.9516\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 153s 510ms/step - loss: 0.0178 - categorical_accuracy: 0.9795 - val_loss: 0.0404 - val_categorical_accuracy: 0.9527\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 153s 512ms/step - loss: 0.0168 - categorical_accuracy: 0.9801 - val_loss: 0.0417 - val_categorical_accuracy: 0.9513\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 153s 512ms/step - loss: 0.0152 - categorical_accuracy: 0.9816 - val_loss: 0.0419 - val_categorical_accuracy: 0.9507\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 152s 509ms/step - loss: 0.0142 - categorical_accuracy: 0.9825 - val_loss: 0.0415 - val_categorical_accuracy: 0.9514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f861404dc40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./out/model.{epoch:02d}-{val_loss:.2f}.h5', verbose=0, save_weights_only=True),\n",
    "]\n",
    "\n",
    "model.fit(train_generator, validation_data = val_generator, validation_steps=100, steps_per_epoch=300, epochs=10, callbacks=callbacks) # 300, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWPNcyPgwl_2"
   },
   "source": [
    "### Resultats - avaluació\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPOE8fTaguPO"
   },
   "outputs": [],
   "source": [
    "testGene = testGenerator(test_path, target_size=(512, 512))\n",
    "results = model.predict(testGene, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkfSD7SMVnUA"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (30,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIw2z80wvVXW"
   },
   "outputs": [],
   "source": [
    "def remove_border_cells(contours, shape):\n",
    "    \"\"\"\n",
    "    Removes the objects from the borders of the image.\n",
    "\n",
    "    A border of an image is the zone near the start or the end of the matrix. \n",
    "    The index of this points are near 0 and near the shape of the image. The \n",
    "    contours checked as a parameter don't has that exactly index so is needed \n",
    "    to has an acceptable error.\n",
    "\n",
    "    Args:\n",
    "        contours: List of numpy arrays, every array its a different contour. The array has two\n",
    "                  columns and many rows as points in the contour. Depending of the appoximation\n",
    "                  method used\n",
    "        shape:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    center_contours = []\n",
    "\n",
    "    for cont in contours:\n",
    "        cont = np.squeeze(cont)\n",
    "        border = not np.all(\n",
    "            (cont[:, 0] > 15) & (cont[:, 1] > 15) & (cont[:, 0] < shape[1] - 15) &\n",
    "            (cont[:, 1] < shape[0] - 15))\n",
    "\n",
    "        if not border:\n",
    "            center_contours.append(np.array([cont]).reshape((cont.shape[0], 1, \n",
    "                                                             cont.shape[1])))\n",
    "\n",
    "    return center_contours\n",
    "\n",
    "def get_iou(ground, prediction, th, debug=False, remove_border_segs = False):\n",
    "  assert ground.shape[2] == prediction.shape[2]\n",
    "  \n",
    "  ground = ground.astype(np.float32) / ground.max()\n",
    "  ious = [0] * ground.shape[2]\n",
    "  \n",
    "  if debug:\n",
    "    fig = plt.figure(1,(16, 12))\n",
    "    idx = 1\n",
    "\n",
    "  for channel_idx in range(0, ground.shape[2]):\n",
    "\n",
    "    channel_gt = ground[:,:, channel_idx]\n",
    "    channel_pred = np.copy(prediction[:, :, channel_idx])\n",
    "    \n",
    "    channel_pred = cv2.resize(channel_pred, (channel_gt.shape[1], channel_gt.shape[0]), interpolation = cv2.INTER_NEAREST) \n",
    "\n",
    "    channel_pred[channel_pred <= th] = 0\n",
    "    channel_pred[channel_pred > th] = 1\n",
    "\n",
    "    if remove_border_segs:\n",
    "      contours, _ = cv2.findContours((channel_pred * 255).astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "      contours = remove_border_cells(contours, channel_pred.shape)\n",
    "\n",
    "      channel_pred = np.zeros_like(channel_pred)\n",
    "      channel_pred = cv2.drawContours(channel_pred, contours, -1, 1, -1)\n",
    " \n",
    "    intersection = cv2.bitwise_and(channel_gt, channel_pred)\n",
    "    intersection_area = np.count_nonzero(intersection)\n",
    "    \n",
    "    union = cv2.bitwise_or(channel_gt, channel_pred)\n",
    "    union_area = np.count_nonzero(union)\n",
    "    \n",
    "    if debug:\n",
    "      l = [channel_gt, channel_pred, intersection, union, (union-intersection)]\n",
    "      titles = [\"GT\", \"PRED\", \"INTERSEC\", \"UNION\", \"DIFF\"]\n",
    "    \n",
    "      for i in range(len(l)):\n",
    "        plt.title(titles[(i-1) % 5])\n",
    "        plt.subplot(4,5, idx)\n",
    "        plt.imshow(l[i], cmap=\"gray\");\n",
    "        idx += 1\n",
    "    \n",
    "    iou = 0\n",
    "    if union_area > 0:\n",
    "        iou = round(intersection_area / union_area, 3)\n",
    "\n",
    "    ious[channel_idx] += iou\n",
    "    \n",
    "  return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vh1u-AJDtS83"
   },
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "\n",
    "ious = []\n",
    "for idx, res in enumerate(results):\n",
    "  gt_image = cv2.imread(\"./unet_color_quatre/test/label/\" + str(idx) + \".png\")\n",
    "  # cv2 reads the images in BGR we convert them into rgb\n",
    "  gt_image = cv2.cvtColor(gt_image, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "  gt_image = decode(gt_image)\n",
    "\n",
    "  iou = get_iou(gt_image, res, alpha)\n",
    "  ious.append(iou)\n",
    "\n",
    "  if idx < 10:\n",
    "    print(\"Image 0\"+ str(idx) + \": \" + str(iou))\n",
    "  else:\n",
    "    print(\"Image \"+ str(idx) + \": \" + str(iou))\n",
    "\n",
    "print(\"###########################################\")\n",
    "print(\"Mean: \", np.mean(ious, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_image = cv2.imread(\"./unet_color_quatre/test/label/\" + str(idx) + \".png\")\n",
    "# cv2 reads the images in BGR we convert them into rgb\n",
    "gt_image = cv2.cvtColor(gt_image, cv2.COLOR_BGR2RGB)\n",
    "gt_image = decode(gt_image)\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "# plt.subplot(4,1,1)\n",
    "# plt.imshow(gt_image[:, :, 0])\n",
    "\n",
    "# plt.subplot(4,1,2)\n",
    "# plt.imshow(gt_image[:, :, 1])\n",
    "\n",
    "# plt.subplot(4,1,3)\n",
    "# plt.imshow(gt_image[:, :, 2])\n",
    "\n",
    "# plt.subplot(4,1,4)\n",
    "plt.imshow(gt_image[:, :, 3])\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jt6t3IqdNhH"
   },
   "source": [
    "La següent cel·la només serveix per evaluar el funcionament de _get_iou_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcRreiGbI76Q"
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "\n",
    "ground = cv2.imread(\"./unet_color_quatre/test/label/\" + str(index) + \".png\")\n",
    "ground = cv2.cvtColor(ground, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "prediction = results[index]\n",
    "th = 0.5\n",
    "ground = decode(ground)\n",
    "get_iou(ground, prediction, th, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NOCoQBBpQk9"
   },
   "outputs": [],
   "source": [
    "#BRUTOR\n",
    "index = 3\n",
    "ground = cv2.imread(\"./unet_color_quatre/test/label/\" + str(index) + \".png\")\n",
    "ground = decode(ground)\n",
    "\n",
    "ground = cv2.resize(ground, (512, 512), interpolation = cv2.INTER_NEAREST) \n",
    "prediction = results[index]\n",
    "\n",
    "g = K.constant(ground)\n",
    "p = K.constant(prediction)\n",
    "        # y_true, y_pred\n",
    "\n",
    "plt.subplot(1,2, 1)\n",
    "plt.imshow(ground, cmap=\"gray\");\n",
    "plt.subplot(1,2, 2)\n",
    "plt.imshow(prediction, cmap=\"gray\");\n",
    "\n",
    "dice_coef_loss(g, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVEzEIVki15l"
   },
   "source": [
    "Visualització dels resultats en format *RAW*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5xLEXPsXEBc"
   },
   "outputs": [],
   "source": [
    "res = results[6] # Canviar aquest index per veure diferents imatges\n",
    "\n",
    "fig = plt.figure(1,(16,12))\n",
    "dim = res.shape[2]\n",
    "for i in range(dim):\n",
    "  plt.subplot(1, dim, i+1)\n",
    "  plt.imshow(res[:,:,i], cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Der_g64wjgjG"
   },
   "source": [
    "Guardar resultats en una carpeta anomenada Out\n",
    "\n",
    "*Nota: Es sobreescriuen els resultats anteriors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_VFRU5OeUXb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!rm -rf out/\n",
    "!mkdir out\n",
    "\n",
    "for idx, r in enumerate(results):\n",
    "  for c_idx in range(0, r.shape[2]):\n",
    "    path = \"./out/\" + str(c_idx) + \"/\"\n",
    "    if not os.path.exists(path): \n",
    "      os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(path + str(idx).zfill(2) + \".png\", r[:,:,c_idx]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2qBqjpkgf_P"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "!zip -r ./out.zip ./out > /dev/null\n",
    "files.download(\"./out.zip\");"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
